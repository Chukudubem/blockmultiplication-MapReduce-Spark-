# blockmultiplication-MapReduce-Spark-
we consider using Hadoop MapReduce and Spark to implement the block-based matrix multiplication. You can assume that each matrix is stored as a text file. Each line of the file corresponds to a block of the matrix in the format of index-content. You may assume all blocks are 2-by-2 and all matrices are 6-by-6. That is each matrix is divided into 9 blocks of equal size (2-by-2 or 4 elements). The content of block is stored in a sparse format: (row index, column index, value) where row and column indexes are relative to the block. All indexes start from 1.
